<?xml version="1.0" encoding="utf-8"?>
<search>
  <entry>
    <title><![CDATA[Go Modules使用教程]]></title>
    <url>%2F2018%2F10%2F17%2Fgo-modules%2F</url>
    <content type="text"><![CDATA[引入https://talks.godoc.org/github.com/myitcv/talks/2018-08-15-glug-modules/main.slide#1 Go Modules介绍Modules是Go 1.11中新增的实验性功能，基于vgo演变而来，是一个新型的包管理工具。 常见的包管理工具 govendor dep glide godep 这些包管理工具都是基于GOPATH或者vendor目录，并不能很好的解决不同版本依赖问题。Modules是在GOPATH之外一套新的包管理方式。 如何激活Modules首先要把go升级到1.11。 升级后，可以设置通过一个环境变量GO111MODULE来激活modules： GO111MODULE=off，go命令行将不会支持module功能，寻找依赖包的方式将会沿用旧版本那种通过vendor目录或者GOPATH模式来查找。 GO111MODULE=on，go命令行会使用modules，而一点也不会去GOPATH目录下查找。 GO111MODULE=auto，默认值，go命令行将会根据当前目录来决定是否启用module功能。这种情况下可以分为两种情形：当前目录在GOPATH/src之外且该目录包含go.mod文件，或者当前文件在包含go.mod文件的目录下面。 当module功能启用时，GOPATH在项目构建过程中不再担当import的角色，但它仍然存储下载的依赖包，具体位置在$GOPATH/pkg/mod。 初始化ModulesGo1.11新增了命令go mod来支持Modules的使用。 123456789101112131415161718192021222324&gt; go help modGo mod provides access to operations on modules.Note that support for modules is built into all the go commands,not just &apos;go mod&apos;. For example, day-to-day adding, removing, upgrading,and downgrading of dependencies should be done using &apos;go get&apos;.See &apos;go help modules&apos; for an overview of module functionality.Usage: go mod &lt;command&gt; [arguments]The commands are: download download modules to local cache edit edit go.mod from tools or scripts graph print module requirement graph init initialize new module in current directory tidy add missing and remove unused modules vendor make vendored copy of dependencies verify verify dependencies have expected content why explain why packages or modules are neededUse &quot;go help mod &lt;command&gt;&quot; for more information about a command. 首先创建一个项目helloworld： 1cd &amp;&amp; mkdir helloworld &amp;&amp; cd helloworld 然后创建文件main.go并写入： 1234567891011package mainimport ( log &quot;github.com/sirupsen/logrus&quot;)func main() &#123; log.WithFields(log.Fields&#123; &quot;animal&quot;: &quot;walrus&quot;, &#125;).Info(&quot;A walrus appears&quot;)&#125; 初始化mod: 1go mod init helloworld 系统生成了一个go.mod的文件： 1module helloworld 然后执行go build，再次查看go.mod文件发现多了一些内容： 123module helloworldrequire github.com/sirupsen/logrus v1.1.1 同时多了一个go.sum的文件： 12345678910github.com/davecgh/go-spew v1.1.1/go.mod h1:J7Y8YcW2NihsgmVo/mv3lAwl/skON4iLHjSsI+c5H38=github.com/konsorten/go-windows-terminal-sequences v0.0.0-20180402223658-b729f2633dfe/go.mod h1:T0+1ngSBFLxvqU3pZ+m/2kptfBszLMUkC4ZK/EgS/cQ=github.com/pmezard/go-difflib v1.0.0/go.mod h1:iKH77koFhYxTK1pcRnkKkqfTogsbg7gZNVY4sRDYZ/4=github.com/sirupsen/logrus v1.1.1 h1:VzGj7lhU7KEB9e9gMpAV/v5XT2NVSvLJhJLCWbnkgXg=github.com/sirupsen/logrus v1.1.1/go.mod h1:zrgwTnHtNr00buQ1vSptGe8m1f/BbgsPukg8qsT7A+A=github.com/stretchr/testify v1.2.2/go.mod h1:a8OnRcib4nhh0OaRAV+Yts87kKdq0PP7pXfy6kDkUVs=golang.org/x/crypto v0.0.0-20180904163835-0709b304e793 h1:u+LnwYTOOW7Ukr/fppxEb1Nwz0AtPflrblfvUudpo+I=golang.org/x/crypto v0.0.0-20180904163835-0709b304e793/go.mod h1:6SG95UA2DQfeDnfUPMdvaQW0Q7yPrPDi9nlGo2tz2b4=golang.org/x/sys v0.0.0-20180905080454-ebe1bf3edb33 h1:I6FyU15t786LL7oL/hn43zqTuEGr4PN7F4XJ1p4E3Y8=golang.org/x/sys v0.0.0-20180905080454-ebe1bf3edb33/go.mod h1:STP8DvDyc/dI5b8T5hshtkjS+E42TnysNCUPdjciGhY= go.sum不是一个锁文件，是一个模块版本内容的校验值，用来验证当前缓存的模块。go.sum包含了直接依赖和间接依赖的包的信息，比go.mod要多一些。 go.mod有四种指令：module，require，exclude，replace。 module：模块名称 require：依赖包列表以及版本 exclude：禁止依赖包列表（仅在当前模块为主模块时生效） replace：替换依赖包列表 （仅在当前模块为主模块时生效） 其他命令1go mod tidy //拉取缺少的模块，移除不用的模块。 1go mod download //下载依赖包 1go mod graph //打印模块依赖图 1go mod vendor //将依赖复制到vendor下 1go mod verify //校验依赖 1go mod why //解释为什么需要依赖 1go list -m -json all //依赖详情]]></content>
      <tags>
        <tag>golang</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[使用scrapyd和spiderkeeper构建scrapy爬虫系统]]></title>
    <url>%2F2018%2F03%2F31%2Fscrapyd-spiderkeeper%2F</url>
    <content type="text"><![CDATA[最近公司爬虫的需求越来越多，所以打算用一套更专业的爬虫框架， 来实现一个爬虫系统，于是就想到了市面上比较流行的框架scrapy。 选择scrapy原因如下： 流行了很久，Github两万多的star 直接支持并发、存储、监控 功能强大，快速上手 相比较其他的解决方案，功能强大、快速上手是我选择scrapy一个很重要的原因。 直接支持并发、存储和监控虽说已经足够强大，但是离我设想的爬虫系统还缺少两个重要的因素，定时任务和UI界面。后来找到了scrapyd和spiderkeeper，帮我解决了这两个问题。于是乎，这个爬虫系统就构建完成了，我们无需再造轮子构建一套爬虫系统，只需把重点放在抓取数据的本身即可。 scrapydscrapyd 是由scrapy 官方提供的爬虫管理工具，使用它我们可以非常方便地上传、控制爬虫并且查看运行日志。 安装1pip install scrapyd 使用在scrapy项目下执行： 1scrapyd scrapyd提供了一套简单的api接口，和一套简单的web页面。 创建爬虫任务： 1curl http://localhost:6800/schedule.json -d project=myproject -d spider=spider2 查看爬虫任务： 在网页中输入：http://localhost:6800/ spiderkeeper主要实现 scrapy 工程的部署，抓取任务状态监控，定时启动爬虫等功能。支持多个 scrapyd 服务 ，方便爬虫集群的管理。 安装1pip install spiderkeeper 使用先启动scrapyd，然后启动spiderkeeper： 123scrapydspiderkeeper --server=http://localhost:6800 然后spiderkeeper默认会在5000端口开放： 1SpiderKeeper startd on 0.0.0.0:5000 username:admin/password:admin with scrapyd servers:http://localhost:6800 打开http://localhost:5000 看到效果图：]]></content>
      <tags>
        <tag>爬虫</tag>
        <tag>scrapy</tag>
        <tag>python</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[区块链：预测2018年]]></title>
    <url>%2F2018%2F02%2F12%2Fblockchain-predictions-for-2018%2F</url>
    <content type="text"><![CDATA[原文 2017年是区块链领域有趣的一年。并非所有事情都如预期发生。包括我在内的许多人预测，2017年是区块链将从概念验证转向现实世界生产的一年。是的，我们在这里看到了一些很大的成功，比如IBM，R3CEV ……但是进入市场的真实世界应用程序的数量远远低于预期。 另一方面有一些意想不到的。今年，区块链的概念开始引起人们的关注。但是这是由比特币和其他加密货币的高光和意外的上涨引发的。而且ICO的繁荣也是出乎意料的。 现在我们即将迎来新的一年，是时候向前看了。2018年区块链和分布式账本技术将会带来什么？比特币和其他加密货币将如何发展。2018年区块链技术的接受程度将如何发展？在这个博客中，我喜欢分享我的想法和观点，了解2018年的发展趋势和发展。让我们走吧！ 1. 加密货币的另一个混乱年份2017年是数字货币炒作的一年。这预计会持续一段时间。2018年对于加密货币来说将是另一个蓬勃发展的一年，但却有许多打嗝。2018年以来，比特币和加密货币整体将继续大幅波动，并可能经历重大调整。主要的问题是：当比特币缺乏实用性时，比特币会在哪里变得明显？ 我们将会看到比特币和其他加密货币的进一步普及。主要是散户投资者推高比特币和其他加密货币的价格。但是通过期货市场和期权降低风险状况，更多的机构投资者终于可以入手了。 私人投资者应该知道。为了维持比特币的持续升值，比例解决方案必须在现实世界中发挥作用。而这不可能在一夜之间发生。这些加密货币都不适合扮演最基本的货币角色，作为一个相对稳定的交易媒介。因此，我们不会看到比特币或其他加密货币成为支付网络。它将被用作投机资产和价值储存。 2.监管机构正在加入2008年将是越来越多的国家加强监管的一年。今年，全世界的立法者和监管机构特别是加密货币领域和ICO已经步入了一个崭新的阶段。韩国政府最近宣布了新的规则来管理比特币交易。韩国是比特币的重要枢纽，旨在规范比特币交易，禁止匿名比特币账户，并希望有可能关闭交易所。早些时候中国宣布关闭一些这些贸易公司。而英美监管人员也表示了类似的警告。 欧洲仍处于监管探索阶段。但越来越多的迹象表明，它们也将变得更加活跃。德国和法国的中央银行表示希望加密货币统治。此外，欧盟委员会已经要求对加密货币“提高警惕”。2018年全球的立法者和监管机构将加强对区块链和加密货币的监督作用。因此，我们将看到越来越多的监管机构采取监管措施来缩小区块链和加密货币违反现行法律的差距。加密交易所将受到审计和监管。有些甚至会被取消。这可能会导致比特币和其他加密货币利率的重大更正。 3. 不是ICO的结束ICO的热潮和代币的推出是2017年令人惊叹的突发事件之一。为了保护投资者，全球监管机构已经开始在ICO中占上风。我们将看到越来越多的国家在2018年对ICO进一步进行监管。虽然这并不意味着ICO的结束，但是ICO将会出现一次倒闭，并且会导致质量的飞跃。ICO将会更加清洁和紧密，投资者将会进行治理并进行尽职调查。简单地在白皮书背后获得资助将会更加困难。投资者将需要合理的业务计划和高度的透明度。监管将触发传统参与者参与。将会有更多的机构资本将全部投入到最高质量的项目中。 随着监管力度的加大，我们也将看到证券代币的崛起。特别是在IPO领域具有丰富经验和专业知识的人士，将会把分词技术作为一个技术平台。 尽管密码领域的监管力度有所增加，但预计区块链作为一项技术将不会受到重大监管的阻碍。基于此，2018年我们将看到更大的成就，区块链不仅在金融领域成为更广泛采用的主流技术，还包括零售，物流和医疗保健。 我们将越来越多地观察区块链的使用情况，包括小型和大型应用程序，以及公共和私营部门的广泛行业。 4. 一些先行者项目将停止/淘汰Forrester表示，2018年将是区块链计划的推算年份。我们将在2018年看到对区块链项目的大量淘汰。将根据标准的商业收益模型对各项举措进行评估。因此，我们期望看到一些项目停止。 一些早期推动者高估了区块链技术在短期内的影响，尤其是那些未能满足长期需求和希望立即进行产业和流程转型的企业和项目，预计将取消投资，并放弃离开区块链竞技场。 其他人对技术及其在长期区块链技术方面的变革潜力有深刻的理解 - 因此更先进和更长远的目光 - 将继续前行。 5. 区块链变得越来越成熟。2018年将是区块链的又一个大年，总体而言，这一年将显示区块链空间的成熟和发展。总的来说，区块链的稳健性和韧性将会增长。 区块链将迅速从勘探转向关键任务生产场景。总的来说，2018年我们预计将会看到更多的区块链应用 - 可能性是无止境的，这个领域的研究和开发的推动力正在加速增长。金融和科技行业的大公司开始在成熟的空间中引入基于区块链和/或分布式账本技术的新平台和工具。我们也预计在今天的主要用例区域之外，区块链的使用案例会大幅增加。 2018年，我们希望区块链成为广泛采用的主流技术。预计2018年区块链的采用将以更快的速度继续。这是一个世界性的现象，早期的生产成功将会浮现。这将使整个行业从金融服务和零售转向物流和医药。 6.更广泛的金融部门应用我们预计2018年金融领域会出现更多的区块链应用。在金融科技领域，两个最有希望的短期用例仍然是支付和贸易融资。 包括代理行在内的大型银行将越来越感兴趣的是区块链支付系统，因为它们受到区块链可能带来的实时处理优势，降低风险状况，降低成本和透明度的优势。正如我们在2017年看到的支付额度最高，并且这种趋势在2018年将持续下去，贸易融资也将于2018年开始在区块链上实现。 而且保险业预计会成为区块链技术的“热门”领域。索赔处理和复杂的多方过程（如代位求偿）将显示区块链自动化的商业价值。 7. 更多用于金融行业之外区块链技术正在其他行业迅速获得牵引力。 制造业和工业预计在制造和生产行业实施区块链将体现第二代数字革命。2018年这一领域最大的区块链增长领域之一是供应链管理，因为它为供应链提供了透明度，特别是在复杂的供应链行业，如汽车和零售行业。与以前的解决方案相比，区块链可用于最大限度地减少物流错误并跟踪供应链中的交付和交易，并提高精确度，安全性和速度。 人力资源在2018年，我们也可以期待区块链进一步被用于招聘和人力资源。在这些领域，已经开发了区块链简历，通过验证候选人的资质和相关经验来简化选择过程。人力资源部门可能会筛选简历，以简化和优化招聘选拔流程。 市场上会有很多平台为用户提供区块链上的“智能”配置文件。这些配置文件不仅包含用户简历，还包括有关其职业成就和成就的信息，竞争性教育计划的证书以及任何其他重要信息。此外，教育机构和雇主可以访问配置文件来确认这些信息，从而使其充分可靠。 健康产业区块链技术也吸引了健康产业的兴趣。2018年应该在这方面取得重大进展。在接下来的几年里，预计区块链技术将被用于很多医疗领域。 IDC HealthInsights在其研究报告“2018年医疗行业的世界预测”中预测，到明年，20％的组织将积极开展区块链项目。到2020年，区块链将用于运营管理以及维护患者数据库。 法律涉及追踪所有权转让的法律工作也将通过实施分布式分类账来提高效率。在2018年，我们可以期待看到区块链被用于管理所有权转移的法律方面。例子包括知识产权和财产契约。 8. 即将推出新的使用案例在2018年，我们还将看到即将推出的区块链技术在旅游（忠诚度计划），政府（身份识别，投票和土地登记），奢侈品和电子防伪（权利管理）等其他领域的新用例，媒体和娱乐。 我们可能会看到Reddit，Medium或YouTube等社交媒体平台整合了区块链标记来奖励和激励他们的内容创作者。2018年也将看到区块链日常应用的第一波浪潮，从Uber的区块链或Airbnb区块链等明显的案例研究开始， 9. 智能合约年区块链有能力将智能合约纳入日常交易 - 加快预先定义的合同的快速和安全的自动验证和处理。我们预计2018年及以后可能会有更多的智能合约应用被推出。具有智能合约技术的新生态系统将成为现有产业之间的整合平台。基于区块链的智能合约可以应用，看似无限的用例。通过创建区块链网络来管理身份，保存记录和保护数字关系。 具体而言，2018年金融行业热门预期的增长领域是智能合约，有可能大幅加快信贷申请和信贷管理的处理时间。去年夏天，IBM，AIG和渣打银行完成了基于区块链的“智能”国际保险政策的试点测试，以监督需要国际合作的复杂保险政策的制定。他们将在2018年大规模地进一步开发这个项目。 10. 反思治理对区块链的兴趣不断增加也将在2018年引发区块链网络治理领域的许多发展。与传统解决方案相比，治理是使区块链项目更加高效和公平的关键因素。这些发展将包括新的共识机制，更新网络更新决策的最新原则，最重要的是，哪个利益相关方应该对网络发展有最终决定权。 通过治理创造适当的激励措施将有助于采纳和鼓励积极的行为，特别是防止诈骗或恶意行为者窃取金钱。这些新的基于区块链的工具和网络越多，使用这些工具和网络的人就越有价值。 11.企业侧重于改变商业模式区块链已经在转变全球金融业。它不仅在改变金融和保险行业，而且正在开始影响其他行业，如医疗保健，零售业，还有公共部门。而且预计在几年的时间里，区块链会在现代商业中具有破坏性的标准。 随着区块链开始转变市场结构，企业越来越关注改变商业模式。在这方面，2018年许多公司将不得不适应他们的业务模式，以满足新市场的要求。公司必须学会更加开放地成为生态系统或更广泛平台上的合作伙伴。这反过来意味着决定他们想要什么样的业务模式 - 无论是基于平台的，基于产品的，全渠道的。 12. 区块链链接物联网和人工智能在2017年期间，公司越来越重视区块链所能提供的新型服务，尤其是区块链结合物联网（IoT）和人工智能（AI）时。最近，基于物联网（IoT）的创新型加密平台IOTA宣布与微软 和其他19个知名行业名称建立合作伙伴关系，共同推动首个物联网加密货币市场投入运营。这种伙伴关系有能力加强个人业务和日常生活的许多领域。区块链的加密和分散性非常有用，可监控物联网上不断增长的设备数量。 这可能成为2018年预期的一个关键趋势的开始 - 区块链技术被纳入不断发展的物联网应用网络。物联网设备将越来越与机器学习，人工智能，雾计算和区块链技术融合。这将有助于企业从仅仅产生增量收益的物联网举措转向那些创造全新商业模式和收入来源的举措。这些市场可能会创造出一种新的市场，在这个市场中，行业孤岛正在降低，有利于广泛的横向结构。这将使公司能够从物联网投资中获得更大的价值，并推动更广泛的应用。 13. 可伸缩性和性能问题的新方法现有区块链技术的关键挑战之一是规模和性能。与传统企业提供的交易速度相比，当前的区块链框架仍然滞后。可扩展性问题正在成为2018年的另一个热门话题。 2018年，我们将看到区块链可扩展性的一些重大突破。将会为下一代分布式应用寻找新的平台。我们将看到当前区块链技术的替代方案将更具可扩展性，速度更快，能耗最小化。甚至是超级区块链等同于万维网。区块链的最大用例之一可能是推出用于保护和验证文档的超级用户。 14. 更加重视安全问题2018年将是企业CIO将越来越多地利用区块链技术潜力的一年。此外，首席信息官，首席信息安全官将更加关注区块链安全，区块链将开始改变欺诈管理和身份验证。blockchain的安全功能真的会进入他们自己的将与他们耦合的物联网。随着连接设备数量的不断增加，2018年将需要区块链的安全架构来保护物联网应用和用户免受复杂的数据泄露。 2018年，网络安全技术的进步，特别是加密技术，密码学和访问控制，再加上区块链将成为安全行业成功的秘诀。随着我们在2018年及以后的发展，越来越多的实体将采用区块链基础设施在数据完整性和透明度方面，因为他们看到了当前使用区块链的好处。 15. 区块链和数据分析2018年也将是一个明确的事实，即在多个行业的各种应用中使用区块链将使高度准确的新数据分析，隐私和身份保护为企业和个人提供重要价值。 例如，在金融和房地产行业，抵押贷款审批流程的分析可以大大简化。借款人可以选择通过区块链与贷方分享准确的个人收入和支出指标。 在健康和保健，制药，生命科学，金融和其他领域还存在着其他强大的可能性。 16. 央行拥抱区块链政府和中央银行长期以来一直保持区块链和密码货币。2018年将是央行将开始接受数字资产作为安全实时交换区块链价值的一年。 使用法定支持数字货币的基于区块链的支付系统将允许中央银行更容易地进行互操作，并与零售银行合作处理跨境支付，并立即达成最终结算。 17. 公共部门将进入区块链竞技场采用区块链时，世界各国政府和机构长期以来都处于旁观之中。但是，情况正在改变。越来越多的这些技术在公共和机构层面得到应用，因为它在提高金融和公共服务效率方面的潜力变得更加明显。各国政府已经开始自己的区块链项目。有些已经在测试区块链作为取代目前投票系统的一种方法。更雄心勃勃的是，区块链技术可以使世界上每个人的身份正式化，不管他们的居住地位如何。 2018年可能是越来越多的政府最终加入区块链潮流并开始密切关注这项技术的一年。因此，我们预测2018年将持续增长和采用。 18. 消费者越来越意识到区块链通过投资比特币，Ether等加密货币，越来越多的消费者正在发现区块链技术及其优势。越来越多的消费者开始看到区块链技术对影响他们的问题的影响。虽然很多人还不知道区块链技术的全部细节，但预计会迅速发生变化。2018年将成为大众公众认识区块链的一年。消费者很快就会对分散系统的概念更加熟悉，并开始意识到这项技术的固有优势。区块链对个人身份和健康的间接好处将在2018年出现。 区块链已经在可以直接使消费者受益的应用程序中使用，例如身份管理，消费者和奢侈品追踪和身份验证。在2018年，公司也将开始设法让消费者追踪他们使用区块链购买的产品的生命周期。 19. 区块链大规模，广泛的发展并不迫在眉睫虽然加密货币不一定是未来，但看起来好像区块链一样。虽然我们预计2018年区块链将成为跨越多个技术领域的潜在破坏者，但每个人都同意，基于区块链（或实际上区块链启发）网络的大规模，广泛部署并非迫在眉睫。 基于区块链的网络的真正转型潜力将需要很长时间才能实现，而非技术和技术原因一样多。需要几年的时间才能解决所有的漏洞，并且技术被认为足够成熟，可以作为企业安全的基础。 那些现在坚持区块链举措的人，不仅要意识到技术还处于发展的早期阶段，还要明白这不是技术真正的问题，而是技术问题。]]></content>
      <tags>
        <tag>区块链</tag>
        <tag>翻译</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[《重返狼群》超越种族的爱，暖心而充满力量]]></title>
    <url>%2F2018%2F02%2F11%2Fchongfanlangqun%2F</url>
    <content type="text"><![CDATA[上次看了《七十七天》后，就一直想找一些川藏题材的电影看一下，于是就找到了《重返狼群》。 说《重返狼群》是一部电影，但更像是一部纪录片，导演用真实的镜头，描写了人类与狼超越种族的爱，深深的震撼了我。 印象最深的是这句话： “还有什么比活着更重要的吗？”“自由。” 当你救了一条小狼之后，你会选择让它去动物园安然度过一生，还是让它回到大自然，面临未知的饥饿和凶险？ 作者做了在我看来最好的选择：她苦苦训练它，在它拥有在大自然中生存的能力后，放它回去，给它自由！ 敬佩作者！ 豆瓣评分 知乎评价]]></content>
      <tags>
        <tag>电影</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[golang变量作用域问题-避免使用全局变量]]></title>
    <url>%2F2018%2F01%2F27%2Fgolang-variable-scope-problem%2F</url>
    <content type="text"><![CDATA[最近遇到了一个变量作用域的问题，一个比较低级的问题，可能作为一个熟手不应该犯这样的低级错误，但是golang的语法特点可能让你稍微不注意就踩坑，嘿嘿。 变量作用域全局变量的作用域是整个包，局部变量的作用域是该变量所在的花括号内，这是一个很基础的问题。我们通常会使用golang的一个语法糖:=来给变量赋值，这种方式可以节省掉我们定义变量的代码，让代码变的更加简洁，但是如果你定义了一个全局变量，又不小心用:=来给它赋值，就会出现一些问题。 问题看下面的代码，定义了一个全局变量t，我想在init()中给他赋值为2，然后在main中使用它。12345678910111213var t intfunc init() &#123; t, err := strconv.Atoi(&quot;2&quot;) if err != nil &#123; log.Fatalln(err) &#125; fmt.Println(&quot;init:&quot;, t)&#125;func main() &#123; fmt.Println(&quot;main:&quot;, t)&#125; 输出：12init: 2main: 0 执行之后，在init和main中打印出了不一样的数字，为什么会不一样呢，可能你仔细一看就知道原因了。很简单，init中的t是用:=生成的，所以t是局部变量，在init函数中覆盖了全局变量t。全局变量t并没有被赋值，它还是原来的0值。 我本想在init中给全局变量t赋值的，却不小心用:=创建了一个局部变量导致全局变量t没有赋值成功，犯了一个低级错误。 解决知道原因之后就容易解决了，我不使用:=就可以了。代码如下：1234567891011121314var t intfunc init() &#123; var err error t, err = strconv.Atoi(&quot;2&quot;) if err != nil &#123; log.Fatalln(err) &#125; fmt.Println(&quot;init:&quot;, t)&#125;func main() &#123; fmt.Println(&quot;main:&quot;, t)&#125; 输出：12init: 2main: 2 没有使用:=之后，init中的t就是全局变量t，给全局变量t赋值为2，main中自然输出的就是2，实现了我最初的目的。 思考这个问题很简单很低级，但是可能一个golang熟手，在代码远比demo要复杂的多的实际项目中，不经意间就可能会犯下这样的错误。 这个问题很难保证说下次一定不会出现的，除非你彻底不用全局变量或者彻底不用:=这样的语法糖。我的建议是这样： 尽量少的使用全局变量。 尽量少的使用:=语法糖。 使用:=的时候要确保左值没有被定义过。]]></content>
      <tags>
        <tag>golang</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[统计信息收集和分布式追踪框架OpenCensus-Go]]></title>
    <url>%2F2018%2F01%2F15%2Fopencensus-go%2F</url>
    <content type="text"><![CDATA[最近在看golang监控这块儿东西，就找到了OpenCensus，Google开源的东东，用这个来作为golang监控的出口应该很不错，学习下先。 OpenCensus 是 Google 开源的一个用来收集和追踪应用程序指标中立厂商的第三方库，能够减少应用的部署与构建成本，尤其适合微服务架构。 OpenCensus 有各种不同的编程语言编写的版本，包括 Go、Java、PHP、C++、Python 等等。它旨在帮助开发者更容易收集和提交跟踪应用程序指标。这是一个中立的单一库发行，可自动收集和跟踪应用指标，可在本地显示，也可将其发送到分析工具。 OpenCensus-Go是golang的实现版本，支持glang1.8或者更新的版本。 安装1$ go get -u go.opencensus.io/... 数据导出OpenCensus可以将数据导出到各种后端。目前OpenCensus支持: Prometheus 统计 OpenZipkin 追踪 Stackdriver TagsTags可以理解为用来传递数据的键值对。它们可以在同一个进程中使用context.Context进行传递，也可以通过编码解码的方式在网络上传输。 新建一个key使用tag.NewKey来新建一个key。 1234key, err := tag.NewKey("my.org/keys/user-os")if err != nil &#123; log.Fatal(err)&#125; 使用该key的人需要知道这个key的name和类型，类型目前只支持string，其他类型将在以后支持。 创建与键key关联的tagMap使用tag.NewMap来创建一个tagMap。 12345678910111213141516osKey, err := tag.NewKey("my.org/keys/user-os")if err != nil &#123; log.Fatal(err)&#125;userIDKey, err := tag.NewKey("my.org/keys/user-id")if err != nil &#123; log.Fatal(err)&#125;tagMap, err := tag.NewMap(ctx, tag.Insert(osKey, "macOS-10.12.5"), tag.Upsert(userIDKey, "cde36753ed"),)if err != nil &#123; log.Fatal(err)&#125; 通过context传递tagMapcontext在golang中是一种很好的传递信息的模块，在OpenCensus中可以通过下面这种方式来传递数据： 1m := tag.FromContext(ctx) 或者 1234567ctx, err = tag.New(ctx, tag.Insert(osKey, &quot;macOS-10.12.5&quot;), tag.Upsert(userIDKey, &quot;fff0989878&quot;),)if err != nil &#123; log.Fatal(err)&#125; Stats统计创建，检索和删除measure创建和加载measure： 1234videoSize, err := stats.Int64(&quot;my.org/video_size&quot;, &quot;processed video size&quot;, &quot;MB&quot;)if err != nil &#123; log.Fatal(err)&#125; 按名称检索measure： 1234m := stats.FindMeasure(&quot;my.org/video_size&quot;)if m == nil &#123; log.Fatalln(&quot;measure not found&quot;)&#125; Traces追踪开启一个span12ctx, span := trace.StartSpan(ctx, &quot;your choice of name&quot;)defer span.End() ProfilesOpenCensus Tags可以作为Profiler标签，该功能适用于Go 1.9及更高版本。 123456789101112ctx, err = tag.New(ctx, tag.Insert(osKey, &quot;macOS-10.12.5&quot;), tag.Insert(userIDKey, &quot;fff0989878&quot;),)if err != nil &#123; log.Fatal(err)&#125;tag.Do(ctx, func(ctx context.Context) &#123; // Do work. // When profiling is on, samples will be // recorded with the key/values from the tag map.&#125;) CPU profile 截图：]]></content>
      <tags>
        <tag>golang</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[grpc-gateway：grpc转换为http协议对外提供服务]]></title>
    <url>%2F2017%2F12%2F27%2Fgolang-grpc-gateway%2F</url>
    <content type="text"><![CDATA[我所在公司的项目是采用基于Restful的微服务架构，随着微服务之间的沟通越来越频繁，就希望可以做成用rpc来做内部的通讯，对外依然用Restful。于是就想到了google的grpc。 使用grpc的优点很多，二进制的数据可以加快传输速度，基于http2的多路复用可以减少服务之间的连接次数，和函数一样的调用方式也有效的提升了开发效率。 不过使用grpc也会面临一个问题，我们的微服务对外一定是要提供Restful接口的，如果内部调用使用grpc，在某些情况下要同时提供一个功能的两套API接口，这样就不仅降低了开发效率，也增加了调试的复杂度。于是就想着有没有一个转换机制，让Restful和gprc可以相互转化。 在网上看到一个解决方案，https://github.com/grpc-ecosystem/grpc-gateway，简单的说就是有一个网关服务器负责转化和代理转发。 如下图： 安装首先要安装ProtocolBuffers 3.0及以上版本。 123456789mkdir tmpcd tmpgit clone https://github.com/google/protobufcd protobuf./autogen.sh./configuremakemake checksudo make install 然后使用go get获取grpc-gateway。 123go get -u github.com/grpc-ecosystem/grpc-gateway/protoc-gen-grpc-gatewaygo get -u github.com/grpc-ecosystem/grpc-gateway/protoc-gen-swaggergo get -u github.com/golang/protobuf/protoc-gen-go 这里最好把编译生成的二进制文件的目录放在$PATH中，可以把$GOPATH/bin放入$PATH中。 示例本示例是基于我的上一篇博客《google的grpc在glang中的使用》中的示例，如果有必要请先了解上一篇博客。 示例代码获取地址:https://github.com/andyidea/go-example。 代码文件结构如下12345678910└── src └── grpc-helloworld-gateway ├── gateway │ └── main.go ├── greeter_server │ └── main.go └── helloworld ├── helloworld.pb.go ├── helloworld.pb.gw.go └── helloworld.proto 我们还是先看一下协议文件。helloworld.proto有一些变动，引入了google官方的api相关的扩展，为grpc的http转换提供了支持。 具体改动如下：123456789101112131415161718192021222324252627282930syntax = &quot;proto3&quot;;option java_multiple_files = true;option java_package = &quot;io.grpc.examples.helloworld&quot;;option java_outer_classname = &quot;HelloWorldProto&quot;;package helloworld;import &quot;google/api/annotations.proto&quot;;// The greeting service definition.service Greeter &#123; // Sends a greeting rpc SayHello (HelloRequest) returns (HelloReply) &#123; option (google.api.http) = &#123; post: &quot;/v1/example/echo&quot; body: &quot;*&quot; &#125;; &#125;&#125;// The request message containing the user&apos;s name.message HelloRequest &#123; string name = 1;&#125;// The response message containing the greetingsmessage HelloReply &#123; string message = 1;&#125; 和之前的proto文件比较，新的文件增了1import &quot;google/api/annotations.proto&quot;; 和 123option (google.api.http) = &#123; post: &quot;/v1/example/echo&quot; body: &quot;*&quot; 这里增加了对http的扩展配置。 然后编译proto文件，生成对应的go文件 1234567cd src/grpc-helloworld-gatewayprotoc -I/usr/local/include -I. \-I$GOPATH/src \-I$GOPATH/src/github.com/grpc-ecosystem/grpc-gateway/third_party/googleapis \--go_out=Mgoogle/api/annotations.proto=github.com/grpc-ecosystem/grpc-gateway/third_party/googleapis/google/api,plugins=grpc:. \helloworld/helloworld.proto 这里生成了helloworld/helloworld.pb.go文件。 helloworld.pb.go是server服务需要的，下一步我们需要使用protoc生成gateway需要的go文件。 123456cd src/grpc-helloworld-gatewayprotoc -I/usr/local/include -I. \-I$GOPATH/src -I$GOPATH/src/github.com/grpc-ecosystem/grpc-gateway/third_party/googleapis \--swagger_out=logtostderr=true:. \helloworld/helloworld.proto 这里生成了helloworld/helloworld.pb.gw.go文件。这个文件就是gateway用来的协议文件，用来做grpc和http的协议转换。 协议文件处理完毕，就需要写gateway代码了。 gateway代码如下： 1234567891011121314151617181920212223242526272829303132333435363738394041package mainimport ( "flag" "net/http" "github.com/golang/glog" "github.com/grpc-ecosystem/grpc-gateway/runtime" "golang.org/x/net/context" "google.golang.org/grpc" gw "grpc-helloworld-gateway/helloworld")var ( echoEndpoint = flag.String("echo_endpoint", "localhost:50051", "endpoint of YourService"))func run() error &#123; ctx := context.Background() ctx, cancel := context.WithCancel(ctx) defer cancel() mux := runtime.NewServeMux() opts := []grpc.DialOption&#123;grpc.WithInsecure()&#125; err := gw.RegisterGreeterHandlerFromEndpoint(ctx, mux, *echoEndpoint, opts) if err != nil &#123; return err &#125; return http.ListenAndServe(":8080", mux)&#125;func main() &#123; flag.Parse() defer glog.Flush() if err := run(); err != nil &#123; glog.Fatal(err) &#125;&#125; 首先echoEndpoint存储了需要连接的server信息，然后将这些信息和新建的server用gw.go中的RegisterGreeterHandlerFromEndpoint进行一个注册和绑定，这时低层就会连接echoEndpoint提供的远程server地址，这样gateway就作为客户端和远程server建立了连接，之后用http启动新建的server，gateway就作为服务器端对外提供http的服务了。 代码到此就完成了，我们测试一下。 先启动greeter_server服务，再启动gateway，这时gatway连接上greeter_server后，对外建立http的监听。 然后我们用curl发送http请求 123curl -X POST -k http://localhost:8080/v1/example/echo -d &apos;&#123;&quot;name&quot;: &quot; world&quot;&#125;&#123;&quot;message&quot;:&quot;Hello world&quot;&#125; 流程如下：curl用post向gateway发送请求，gateway作为proxy将请求转化一下通过grpc转发给greeter_server，greeter_server通过grpc返回结果，gateway收到结果后，转化成json返回给前端。 这样，就通过grpc-gateway完成了从http json到内部grpc的转化过程。]]></content>
      <tags>
        <tag>golang</tag>
        <tag>rpc</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[google的grpc在golang中的使用]]></title>
    <url>%2F2017%2F12%2F10%2Fgolang-grpc%2F</url>
    <content type="text"><![CDATA[GRPC是google开源的一个高性能、跨语言的RPC框架，基于HTTP2协议，基于protobuf 3.x，基于Netty 4.x。 前面写过一篇golang标准库的rpc包的用法，这篇文章接着讲一下google的grpc。 介绍在 gRPC 里客户端应用可以像调用本地对象一样直接调用另一台不同的机器上服务端应用的方法，使得您能够更容易地创建分布式应用和服务。 使用grpc的优点很多，支持多种语言，二进制的数据可以加快传输速度，基于http2的多路复用可以减少服务之间的连接次数，和函数一样的调用方式也有效的提升了开发效率。 grpc提供有go版本，下面介绍一下grpc在golang中的使用。 安装grpc支持1.5及以上版本。 用以下命令安装grpc-go: 1go get google.golang.org/grpc 安装Protocol Buffers v3 去https://github.com/google/protobuf/releases下载最新的稳定的版本，然后解压缩，把里面的文件放到$PATH中。 安装插件 1go get -u github.com/golang/protobuf/&#123;proto,protoc-gen-go&#125; 别忘了将$GOPATH/bin添加到$PATH中： 1export PATH=$PATH:$GOPATH/bin 示例示例代码获取地址:https://github.com/andyidea/go-example。 代码文件结构如下123456789101112├── bin│ ├── grpc-client│ └── grpc-server└── src └── grpc-helloworld ├── greeter_client │ └── main.go ├── greeter_server │ └── main.go └── helloworld ├── helloworld.pb.go └── helloworld.proto grpc-helloworld里有三个包，greeter_client是客户端代码，greeter_server是服务端代码，helloworld是协议文件。 先看下协议。 helloworld.proto 1234567891011121314151617181920212223syntax = &quot;proto3&quot;;option java_multiple_files = true;option java_package = &quot;io.grpc.examples.helloworld&quot;;option java_outer_classname = &quot;HelloWorldProto&quot;;package helloworld;// The greeting service definition.service Greeter &#123; // Sends a greeting rpc SayHello (HelloRequest) returns (HelloReply) &#123;&#125;&#125;// The request message containing the user&apos;s name.message HelloRequest &#123; string name = 1;&#125;// The response message containing the greetingsmessage HelloReply &#123; string message = 1;&#125; 协议中定义了两个结构体HelloRequest和HelloReply，还有一个函数SayHello，函数的参数是HelloRequest，返回HelloReply。 在src/下用下面命令生成协议的go文件： 1protoc -I helloworld/ helloworld/helloworld.proto --go_out=plugins=grpc:helloworld 这样就生成了helloworld.pb.go协议文件。 接着我们看下服务器端的代码： 12345678910111213141516171819202122232425262728293031323334353637package mainimport ( "log" "net" "golang.org/x/net/context" "google.golang.org/grpc" pb "grpc-helloworld/helloworld" "google.golang.org/grpc/reflection")const ( port = ":50051")// server is used to implement helloworld.GreeterServer.type server struct&#123;&#125;// SayHello implements helloworld.GreeterServerfunc (s *server) SayHello(ctx context.Context, in *pb.HelloRequest) (*pb.HelloReply, error) &#123; return &amp;pb.HelloReply&#123;Message: "Hello " + in.Name&#125;, nil&#125;func main() &#123; lis, err := net.Listen("tcp", port) if err != nil &#123; log.Fatalf("failed to listen: %v", err) &#125; s := grpc.NewServer() pb.RegisterGreeterServer(s, &amp;server&#123;&#125;) // Register reflection service on gRPC server. reflection.Register(s) if err := s.Serve(lis); err != nil &#123; log.Fatalf("failed to serve: %v", err) &#125;&#125; 服务器端主要逻辑就是实现之前协议中的SayHello方法，这里是将字符串Hello和参数拼接在一起返回。 协议生成的go文件给了一个RegisterGreeterServer方法，我们用这个方法绑定实现函数的结构体和server。 然后是客户端代码： 123456789101112131415161718192021222324252627282930313233343536package mainimport ( "log" "os" "golang.org/x/net/context" "google.golang.org/grpc" pb "grpc-helloworld/helloworld")const ( address = "localhost:50051" defaultName = "world")func main() &#123; // Set up a connection to the server. conn, err := grpc.Dial(address, grpc.WithInsecure()) if err != nil &#123; log.Fatalf("did not connect: %v", err) &#125; defer conn.Close() c := pb.NewGreeterClient(conn) // Contact the server and print out its response. name := defaultName if len(os.Args) &gt; 1 &#123; name = os.Args[1] &#125; r, err := c.SayHello(context.Background(), &amp;pb.HelloRequest&#123;Name: name&#125;) if err != nil &#123; log.Fatalf("could not greet: %v", err) &#125; log.Printf("Greeting: %s", r.Message)&#125; 客户端的思路也很清晰，建立一个rpc客户端连接，将这个连接用pb.NewGreeterClient和协议绑定，返回一个client对象，用这个对象就可以调用远程的函数了。 调用输出如下： 1Greeting: Hello world 示例到此结束。示例代码获取地址:https://github.com/andyidea/go-example。]]></content>
      <tags>
        <tag>golang</tag>
        <tag>rpc</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[homebrew常用命令]]></title>
    <url>%2F2017%2F02%2F11%2Fhomebrew-commond%2F</url>
    <content type="text"><![CDATA[安装 1ruby -e &quot;$(curl -fsSL https://raw.github.com/Homebrew/homebrew/Go/install)&quot; 搜索 1brew search XXX 查询 1brew info XXX 更新自己 1brew update 是否有新版本 1brew outdated 列出所有安装的软件里可以升级的软件 升级软件 1brew upgrade 升级所有可以升级的软件们 1brew upgrade XXX 升级某个软件 清理 1brew cleanup 清理不需要的版本极其安装包缓存]]></content>
      <tags>
        <tag>homebrew</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Cocos2d-x中的模糊(Blur)]]></title>
    <url>%2F2017%2F02%2F11%2Fcocos2d-x-blur-shader%2F</url>
    <content type="text"><![CDATA[模糊效果在游戏中经常会用到，有的为了突出前景会把背景给模糊化，有的是因为一些技能需要模糊效果。模糊是shader中较为简单的一种应用。cocos2dx 3.x给的demo中，就有sprite的模糊的效果。 先说下这个模糊算法的大致思路，我们在片段着色器中可以得到当前像素点的颜色值，要想让这个颜色变得模糊，就要让它与它周围的像素点的颜色稍微接近一点，那么我们就需要拿到这个像素点周围的像素点的颜色值，我们把这些个像素点的值加起来取平均值，就得到了一个区域内的平均颜色。如果直接使用这个颜色的话，最终的效果会变得很模糊，如果我们只是想稍微模糊一点的话，就要让这个平均值更接近于当前像素点原本的颜色，为此，我们取均值的时候对每个像素点增加了一个权重的定义，当前像素点的权重最高，依次向周围减弱，使得最后得到的均值的颜色更接近于当前像素点原始的颜色。 看代码： 12345678910111213141516171819202122232425262728293031323334353637383940414243444546#ifdef GL_ESprecision mediump float;#endifvarying vec4 v_fragmentColor;varying vec2 v_texCoord;uniform vec2 resolution;//模糊对象的实际分辨率uniform float blurRadius;//半径uniform float sampleNum;//间隔的段数vec4 blur(vec2);void main(void)&#123; vec4 col = blur(v_texCoord); //* v_fragmentColor.rgb; gl_FragColor = vec4(col) * v_fragmentColor;&#125;vec4 blur(vec2 p)&#123; if (blurRadius &gt; 0.0 &amp;&amp; sampleNum &gt; 1.0) &#123; vec4 col = vec4(0); vec2 unit = 1.0 / resolution.xy;//单位坐标 float r = blurRadius; float sampleStep = r / sampleNum; float count = 0.0; //遍历一个矩形，当前的坐标为中心点，遍历矩形中每个像素点的颜色 for(float x = -r; x &lt; r; x += sampleStep) &#123; for(float y = -r; y &lt; r; y += sampleStep) &#123; float weight = (r - abs(x)) * (r - abs(y));//权重，p点的权重最高，向四周依次减少 col += texture2D(CC_Texture0, p + vec2(x * unit.x, y * unit.y)) * weight; count += weight; &#125; &#125; //得到实际模糊颜色的值 return col / count; &#125; return texture2D(CC_Texture0, p);&#125; 精度限定符和varying变量等的一些基础的知识在前面的博客中遇到的已经说过。uniform变量是顶点着色器和片段着色器共享使用的变量，uniform的值不能被改变。uniform变量是由宿主程序设置的，代码如下： 123456789void EffectBlur::setTarget(EffectSprite *sprite)&#123; Size size = sprite-&gt;getTexture()-&gt;getContentSizeInPixels(); _glprogramstate-&gt;setUniformVec2("resolution", size);#if (CC_TARGET_PLATFORM != CC_PLATFORM_WINRT) _glprogramstate-&gt;setUniformFloat("blurRadius", _blurRadius); _glprogramstate-&gt;setUniformFloat("sampleNum", _blurSampleNum);#endif&#125; 这里宿主程序设置了resolution，blurRadius和sampleNum三个uniform变量。渲染的时候，顶点着色器和片段着色器都可以用到这三个变量的值。resolution是当前渲染node的实际分辨率。blurRadius是像素点模糊处理的参考矩形的半径sampleNum选择像素点的间隔的数量，相邻像素点的间距等于blurRadius / sampleNum blur函数就是计算该像素点的最终颜色，参数p是当前像素点的坐标，我们以p点为中点以2r为边长得到一个矩形，这个矩形中每隔sampleStep长度的像素点是当前像素点的颜色参考像素。每个像素点会乘以一个weight权重，这个weight越靠近p点值越高，目的是为了让最终的值更接近于p点的像素颜色，然后各个像素点乘以权重后的颜色加起来，得到col，把各个权重也加起来得到count。最终的颜色值就是col/count。 效果图如下：模糊前：模糊后：]]></content>
      <tags>
        <tag>cocos2d-x</tag>
        <tag>shader</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[《架构即未来》中最常用的15个架构原则]]></title>
    <url>%2F2017%2F02%2F11%2Fframework-15-principle%2F</url>
    <content type="text"><![CDATA[《架构即未来》这本书的第12章简单阐述了架构设计的一些常用的原则（后面章节会详细阐述）。这些原则中很多都是在架构一开始的设计中就要考虑进去的，这样在出现任何问题时，我们都能够及时的处理，和把问题影响的范围有效的缩小。否则就像我现在的项目，一开始设计时，考虑的很少，出问题时，没有做到及时的反馈，和缩小影响范围，只能在事故的代价中将所需要的原则添加进来，慢慢完善。 1.N+1设计 要确保任何你所开发的系统在发生故障时，至少有一个冗余的实例。 一个实例确实很危险，当这个实例出现不明原因的问题不能对外服务，需要debug的时候，如果优先debug，那当前实例就要暂停服务直到你找到问题为止。如果你直接重启实例恢复服务，就没有事故现场进行debug了。而这时如果有一个冗余的实例，就可以先让冗余的实例对外服务，事故现场的环境也得以保留。 多个实例来做负载均衡也是一种不错的选择。 2.回滚设计 确保系统可以回滚到以前发布过的任何版本。 以前做游戏的时候经常遇到回滚，有时候是数据库回滚，有时候是服务器端回滚，一般都是回滚到上个版本。 3.禁用设计 能够关闭任何发布的功能。 当一个功能出现严重问题不得不关闭时，如果关闭整个系统代价就有点大了，所有要有单个功能的开关。像商城系统的支付功能就一定要有开关，如果出现比较严重的bug，可以关闭支付而不影响下单。 4.监控设计 在设计阶段就必须要考虑监控，而不是在实施完成之后补充。 如果监控做的好，不仅能发现服务的死活，检查日志文件，还能收集系统相关的数据，评估终端用户的响应时间。如果系统和应用在设计和构建时就考虑好监控，那么即使不能自我修复，也至少可以自我诊断。 5.设计多活数据中心 不要被一个数据中心的解决方案把自己限制住。 有钱就多建一个，让股东放心。 6.只用成熟的技术 只用确实好用的技术。 不管用什么技术，都要确保是一个成熟的技术。也许某个新技术有众多优点，比如，降低开发成本，提高开发效率，提高可扩展能力，减少终端用户的响应时间。但是，只要这项技术故障率比较高，就绝不能使用。 7.异步设计 只有在绝对必要的时候才进行同步调用。 异步适合并发。 8.无状态系统 只有当业务确实需要的时候，才使用状态。 无状态的系统更利于扩展，更利于做负载均衡。 9.水平扩展非垂直升级 永远不要依赖更大、更快的系统。 微服务是水平扩展的一个例子，不要把所有的功能都集中在一个系统里面。必要的时候把需求分为多个系统，而不是升级原有的系统。 10.设计至少有两个步骤的前瞻性 在扩展性问题发生前考虑好下一步的行动计划。 想的更远一点，就能减少重构的次数。 11.非核心则购买 如果不是你最擅长的，也提供不了差异化的竞争优势则直接购买。 云服务这种的就购买好了。 12.使用商品化硬件 在大多数情况下，便宜的是最好的。 硬件这块儿，满足需求即可，在必要的时候增加配置。 13.小构建，小发布，快试错 全部研发要小构建，不断迭代，让系统不断地成长。 小版本的失败率较低，因为失败率与解决方案中的变更数量直接相关。 14.隔离故障 实现隔离故障设计，通过断路保护避免故障传播和交叉影响。 避免多系统之间的互相影响，这个很重要。 15.自动化 设计和构建自动化的过程。如果机器可以做，就不要依赖于人。 人常犯错误，更令人沮丧的是，他们往往会以不同的方式多次犯同样的错误。]]></content>
      <tags>
        <tag>architect</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Cocos2d-x中的sprite描边(Outline)]]></title>
    <url>%2F2017%2F02%2F11%2Fcocos2d-x-outline-shader%2F</url>
    <content type="text"><![CDATA[Cocos2d-x 3.x的label使用了freetype字体引擎（http://www.freetype.org/），可以很轻松的实现描边和阴影效果。所以本篇文章只针对于`sprite`来实现描边效果。 官方demo中描边shader没有看懂，看效果好像是有点问题，透明的部分变成了黑色。作者也没有怎么解释，直接丢了一个网址出来（http://www.idevgames.com/forums/thread-3010.html），看样子是参考了这个帖子。 后来从网上别人的博客中找到了一遍关于描边shader的文章，这篇文章用的方法跟我想的差不多，优点是很容易理解，缺点是相对于官方demo给的描边shader效率上差了点。原文地址：http://blog.csdn.net/u011281572/article/details/44999609。 原文的代码考虑了label的描边，这个对于现在的cocos3.x版本来说有点多余，我就对原文的代码做了些改动，去掉了label描边的那块儿代码，有些逻辑也做了一些改变，使得更容易理解一些。 下面是我改动后的代码： 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152varying vec4 v_fragmentColor; // vertex shader传入，setColor设置的颜色varying vec2 v_texCoord; // 纹理坐标uniform float outlineSize; // 描边宽度，以像素为单位uniform vec3 outlineColor; // 描边颜色uniform vec2 textureSize; // 纹理大小（宽和高），为了计算周围各点的纹理坐标，必须传入它，因为纹理坐标范围是0~1// 判断在这个角度上距离为outlineSize那一点是不是透明int getIsStrokeWithAngel(float angel)&#123; int stroke = 0; float rad = angel * 0.01745329252; // 这个浮点数是 pi / 180，角度转弧度 vec2 unit = 1.0 / textureSize.xy;//单位坐标 vec2 offset = vec2(outlineSize * cos(rad) * unit.x, outlineSize * sin(rad) * unit.y); //偏移量 float a = texture2D(CC_Texture0, v_texCoord + offset).a; if (a &gt;= 0.5)// 我把alpha值大于0.5都视为不透明，小于0.5都视为透明 &#123; stroke = 1; &#125; return stroke;&#125;void main()&#123; vec4 myC = texture2D(CC_Texture0, v_texCoord); // 正在处理的这个像素点的颜色 if (myC.a &gt;= 0.5) // 不透明，不管，直接返回 &#123; gl_FragColor = v_fragmentColor * myC; return; &#125; // 这里肯定有朋友会问，一个for循环就搞定啦，怎么这么麻烦！其实我一开始也是用for的，但后来在安卓某些机型（如小米4）会直接崩溃，查找资料发现OpenGL es并不是很支持循环，while和for都不要用 int strokeCount = 0; strokeCount += getIsStrokeWithAngel(0.0); strokeCount += getIsStrokeWithAngel(30.0); strokeCount += getIsStrokeWithAngel(60.0); strokeCount += getIsStrokeWithAngel(90.0); strokeCount += getIsStrokeWithAngel(120.0); strokeCount += getIsStrokeWithAngel(150.0); strokeCount += getIsStrokeWithAngel(180.0); strokeCount += getIsStrokeWithAngel(210.0); strokeCount += getIsStrokeWithAngel(240.0); strokeCount += getIsStrokeWithAngel(270.0); strokeCount += getIsStrokeWithAngel(300.0); strokeCount += getIsStrokeWithAngel(330.0); if (strokeCount &gt; 0) // 四周围至少有一个点是不透明的，这个点要设成描边颜色 &#123; myC.rgb = outlineColor; myC.a = 1.0; &#125; gl_FragColor = v_fragmentColor * myC;&#125; 大致的逻辑是：先判断当前像素是否透明，如果不透明则直接返回。如果是透明像素，就判断这个点周围12个方向，每个方向距离当前像素距离是outlineSize的像素点是否透明，只要有一个是非透明像素，就把当前像素点设为描边的颜色，并设置成非透明。效果如下：]]></content>
      <tags>
        <tag>cocos2d-x</tag>
        <tag>shader</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[使用hugo和docker打造静态博客解决方案]]></title>
    <url>%2F2017%2F02%2F11%2Fhugo-docker-environment%2F</url>
    <content type="text"><![CDATA[前言今年是转型的一年，告别了游戏行业，开始使用golang做起了web应用。golang整体体验下来还是很不错的，接近C的性能、天生拥有的高并发能力、简洁的语法以及相对C/C++而言简化的指针，使得这门语言在开发效率和运行效率两方面都有着不错的表现。相对于C语言而言，golang有着接近于python的快速开发和快速迭代的能力，而相对于python来说，golang有着更好的性能和更强大的并发能力。相信随着开源社区的不断壮大，golang会慢慢的流行起来。 hugo是一个静态博客的生成工具，和hexo类似。因为hugo是用golang写的，在github上面有着一万多的star数量，所以我建立独立博客的时候选择了hugo而不是hexo来作为静态博客的engine。 docker是PaaS提供商dotCloud开源的一个基于LXC的高级容器引擎，源代码托管在Github上,基于go语言。这个概念最近比较火，所以我就抽空学习了一下docker并用它作为我的个人博客blog.andyli.me的部署方案。大致介绍下部署的方案，我一共用到了两个docker容器，一个容器跑nginx，另一个跑hugo生成静态页面，两个docker容器跑在一个cent os的vps上面。 一、hugo的安装hugo是用golang写的，支持多平台。 可直接参考hugo中文文档。 1.Mac OSmac上可以使用HomeBrew安装hugo，非常简单， 只需要执行下面这句命令即可。 1brew update &amp;&amp; brew install hugo 2.Linuxlinux安装也比较简单，因为hugo的环境就是一个二进制包，没有依赖，所以直接下载下来，放到usr/local/bin中就可以了 1.去网站https://github.com/spf13/hugo/releases下载对应的包，比如hugo_x.xx_linux-64bit.tgz。 2.解压缩后将二进制文件改名为hugo 3.将这个二进制文件移动到usr/local/bin目录中 3.Windowshugo在windows下面是一个.exe文件，也是没有依赖的。 1.去网站https://github.com/spf13/hugo/releases下载对应的包，比如hugo_x.xx_linux-64bit.tgz。 2.解压缩后得到hugo.exe文件 3.在C:\中创建文件夹C:\hugo，将hugo.exe移动到C:\hugo中 4.把目录C:\hugo添加到环境变量PATH中 4.源码安装1.安装git和go 1.5+ 2.export GOPATH=$HOME/go 3.go get -v github.com/spf13/hugo 4.将目录$HOME/go/bin添加到环境变量PATH中 5.检查安装是否成功在命令行下执行hugo命令，如果得到类似下面结果，则说明你已经成功安装了Hugo： 12$ hugo versionHugo Static Site Generator v0.15-DEV BuildDate: 2015-09-20T23:53:39+08:00 二、hugo的使用hugo安装好之后，我们看看怎么来快速的使用它。 1.创建站点使用下面命令在当前目录下创建一个站点bookshelf 1$ hugo new site bookshelf 然后进入创建好的目录bookshelf中，执行一下tree -a看到目录结构是这样的： 123456789.|-- archetypes|-- config.toml|-- content|-- data|-- layouts`-- static5 directories, 1 file 2.新增博客内容执行下面命令创建一篇博客： 1$ hugo new post/good-to-great.md 创建成功会提示： 1/Users/shekhargulati/bookshelf/content/post/good-to-great.md created 创建好的文件位于content中，congtent目录结构如下: 12345content`-- post `-- good-to-great.md1 directory, 1 file 3.运行博客运行如下命令来启动服务： 1$ hugo server 启动成功会显示如下信息： 12345678910110 of 1 draft rendered0 future content0 pages created0 paginator pages created0 tags created0 categories createdin 9 msWatching for changes in /Users/shekhargulati/bookshelf/&#123;data,content,layouts,static&#125;Serving pages from memoryWeb Server is available at http://localhost:1313/ (bind address 127.0.0.1)Press Ctrl+C to stop 打开站点http://localhost:1313/访问你的博客。 4.选择皮肤去站点http://themes.gohugo.io/选择适合你的皮肤。 三、使用Docker部署我使用了两个镜像来部署，一个镜像部署博客生成静态文件，另一个镜像运行nginx。 1.部署博客首先看一下静态文件镜像的dockerfile： 123456789101112131415161718192021222324252627FROM debian:jessieRUN apt-get update &amp;&amp; apt-get install --no-install-recommends -y \ ca-certificates \ curl \ mercurial \ git-coreRUN curl -s https://storage.googleapis.com/golang/go1.6.linux-amd64.tar.gz | tar -v -C /usr/local -xzENV GOPATH /goENV GOROOT /usr/local/goENV PATH $PATH:/usr/local/go/bin:/go/binRUN apt-get update &amp;&amp; apt-get install --no-install-recommends -y bzrRUN go get github.com/spf13/hugoRUN git clone https://github.com/andyidea/blog.andyli.me.git /blogRUN cd /blog &amp;&amp; git submodule update --init --recursiveWORKDIR /blogVOLUME [&quot;/var/www/blog&quot;]CMD [&quot;sh&quot;, &quot;run.sh&quot;] dockerfile写好之后，我们就可以创建镜像了。 把dockerfile放到服务器上，然后运行docker build 1docker build -t blog . 执行完后，就创建了名字叫blog的镜像，接下来我们根据生成的镜像来生成容器： 1docker run --name blog blog 这个命令的意思是，根据镜像blog生成一个名字叫做blog的容器。使用docker ps就可以看到正在运行的容器了。 运行到这一步说明静态的博客文件已经生成，下一步让nginx作为静态博客的server。 2.部署nginxNginx的dockerfile： 123FROM nginxADD nginx/ /etc/nginx dockerfile很简单，ADD这步操作是为了把config文件放到nginx中，具体可参考demohttps://github.com/andyidea/dockerfile/tree/master/nginx 同样的，我们把dockerfile放到服务器上并执行 1docker build -t nginx . 镜像生成好后，生成容器 1docker run -p 80:80 -d --name nginx --volumes-from blog nginx 这个命令的意思是，使用镜像nginx生成一个容器，将宿主机80端口映射到docker容器中的80端口，-d是运行在后台，–volumes-from 是使用blog容器的卷，也就是blog dockerfile中的VOLUME [&quot;/var/www/blog&quot;]命令。 至此，博客的部署完毕。 3.更新博客使用下面的命令来更新博客： 1docker restart blog]]></content>
      <tags>
        <tag>hugo</tag>
        <tag>docker</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[lua和c的亲密接触]]></title>
    <url>%2F2017%2F02%2F11%2Flua-and-c%2F</url>
    <content type="text"><![CDATA[介绍 lua和c的亲密接触，靠的是一个虚拟栈。lua通过这个虚拟栈来实现和c之间值的互传。栈上的每一个元素是一个lua值（nil，number，string…）。 当lua调用c函数的时候，这个函数会得到一个新的栈，这个栈独立于c函数本身的栈，也独立于lua自己的栈。它里面包含了lua要传给c的所有参数，然后c函数会把返回的结果放入这个栈中返回给调用者。对于栈的查询操作，如果按照栈的规则，只能拿到栈顶的元素。但这里和常规的栈有一些差异。就是可以用一个索引来指向栈上的任何元素。正数的索引（1...n）指向从栈底到栈顶元素，1就是最先入栈的元素，n就是栈顶的元素，负数的索引（-1...-n）指向从栈顶到栈底的元素，-1就是栈顶元素，-n就是最先入栈的元素。通过这两种索引方式可以很方便的获取栈中的元素。 基本操作lua和c之间的交互的桥梁是一个虚拟栈，这个虚拟栈在lua的c api中为lua_State，下面的代码展示了从创建栈，元素入栈，根据索引获取栈中元素的值的过程，这也是lua_State的最基本的操作。 123456789101112131415161718lua_State *L = luaL_newstate();//创建一个新的栈lua_pushstring(L, "muzixiaoxin"); //把一个字符串压入栈lua_pushnumber(L, 875);//把一个整型压入栈//现在栈内有两个元素，栈底是字符串"muzixiaoxin"，栈顶是整型875//"muzixiaoxin"的索引就是1，或者-2//855的索引就是2，或者-1if (lua_isstring(L, 1))&#123;//判断栈底的元素是不是字符串 printf("%s\n",lua_tostring(L, 1));//如果是字符串就转换成字符串输出&#125;if (lua_isnumber(L, -1))&#123;//判断栈顶元素是不是number类型 printf("%d", lua_tonumber(L, 2));//如果是就转换成number类型输出&#125;lua_close(L); //记得不需要的时候要释放掉 提示：更多的相关函数请参考lua中文手册 c调用luac调用lua这种情况我见到的比较少，一般都是用lua虚拟机直接跑脚本。也有一些把lua作为配置文件给c用的。举个例子，新建一个lua文件test.lua 12name = "muzixiaoxin"version = 1003 c需要通过lua c api把这个文件加载进来，然后执行，执行的结果存在一个栈中， 去这个栈中拿到变量的值。看下面的c代码： 12345678910111213141516lua_State *L = luaL_newstate();int err = luaL_loadfile(L, "test.lua"); //把lua文件加载成代码块，只加载不运行if (err)&#123; return;&#125;err = lua_pcall(L, 0, 0, 0);//运行加载的代码块if (err)&#123; return;&#125;lua_getglobal(L, "name"); //把全局变量name的值压入栈顶printf("%s\n", lua_tostring(L, -1));//取出栈顶元素打印结果为:muzixiaoxinlua_close(L); //记得不需要的时候要释放掉 lua调用c方法lua调用c有些麻烦，要写一个固定格式的方法来供lua调用。我们先简单的写个求和的c方法： 12345//计算求和的方法static intsum(int a, int b)&#123; return a + b;&#125; 这个方法就是求两个整型的和。我们要让lua使用这个方法，就要先把这个方法注册给lua的状态机，但注册给lua状态机的方法要求有固定的参数和固定的返回值，参数要是一个lua虚拟栈，这个虚拟栈存放着lua传过来的参数，lua调用的返回值也要通过这个虚拟栈返回给lua，最后的返回值要求是一个int值，存着返回给lua变量的个数。我们看写好的方法： 123456789101112131415161718192021//lua调用的方法static intlsum(lua_State *L)&#123; int a = (int)lua_tonumber(L, -1);//lua调用的参数之一 int b = (int)lua_tonumber(L, -2);//lua调用的参数之一 lua_pushnumber(L, sum(a, b));//把计算的加过压栈 return 1;//返回返回值的个数&#125;下一步是吧lsum这个方法注册给lua状态机：lua_State *L = luaL_newstate();luaL_openlibs(L);//打开L中的所有标准库，这样就可以使用print方法lua_register(L, "sum", lsum);//把c函数lsum注册为lua的一个全局变量sumint err = luaL_dofile(L, "test.lua"); //把lua文件加载成代码块，并运行if (err)&#123; return;&#125;lua_close(L); test.lua的内容是： 1print("1 + 2 = " .. sum(1,2)) 最后的输出结果： 总结一下，就是，你要通过一个中间函数（像lsum这种）对lua虚拟栈进行操作来实现lua调用c的方法。 提示：更多的lua c api请参考lua中文手册]]></content>
      <tags>
        <tag>lua</tag>
        <tag>c</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[nginx多域名配置]]></title>
    <url>%2F2017%2F02%2F11%2Fnginx-lot-of-domain-config%2F</url>
    <content type="text"><![CDATA[nginx多域名配置是在配置文件中建立多个server配置，在每个server配置中用server_name来对域名信息进行过滤。举个例子，下面是一个conf文件： 1234567891011121314151617server &#123; listen 80; server_name www.web1.com; #绑定域名 index index.htm index.html index.php; #默认文件 root /home/www.web1.com; #网站根目录include location.conf; #调用其他规则，也可去除&#125;server &#123; listen 80; server_name www.web2.com; #绑定域名 index index.htm index.html index.php; #默认文件 root /home/www/web2.com; #网站根目录include location.conf; #调用其他规则，也可去除&#125; 以上配置信息就是在一个nginx配置中最简单的多域名配置方法，关于server_name，nginx官方还提供了很多正则匹配的过滤方式，详情请看nginx官方文档。 ##注意事项特别要注意的是，在nginx的配置文件中只有一个server配置的时候，server_name是无效的，也就是说任何域名绑定了这个IP的时候，无论server_name填什么域名，都会匹配到这个唯一的server。只有在多个server的时候，server_name才会有效。]]></content>
      <tags>
        <tag>nginx</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[golang中的reflect包用法]]></title>
    <url>%2F2017%2F02%2F11%2Fgolang-reflect%2F</url>
    <content type="text"><![CDATA[最近在写一个自动生成api文档的功能，用到了reflect包来给结构体赋值，给空数组新增一个元素，这样只要定义一个input结构体和一个output的结构体，并填写一些相关tag信息，就能使用程序来生成输入和输出的相关文档。 介绍reflect包是golang中很重要的一个包,实现了在运行时允许程序操纵任意类型对象的功能。可以看下文档简单了解一下。 在reflect中,最重要的是Value类,只有先获取到一个对象或者变量的Value对象后,我们才可以对这个对象或者变量进行更进一步的分析和处理。我们可以使用reflect.ValueOf()方法获取Value对象。 12345678910var i intvalue := reflect.ValueOf(i) // 使用ValueOf()获取到变量的Value对象type S struct &#123; a string&#125;var s Svalue2 := reflect.ValueOf(s) // 使用ValueOf()获取到结构体的Value对象 获取到对象或者变量的Value对象后，我们就可以对他们进一步的操作了。 1.获取对象或者变量的类型(Value.Type()和Value.Kind())Value.Type()和Value.Kind()这两个方法都可以获取对象或者变量的类型，如果是变量的话，使用这两个方法获取到的类型都是一样，差别是结构体对象，举个例子看一下： 12345678910111213141516var i intvalue := reflect.ValueOf(i)log.Println(value.Type()) //输出:intlog.Println(value.Kind()) //输出:inttype S struct &#123; a string&#125;var s Svalue2 := reflect.ValueOf(s) // 使用ValueOf()获取到结构体的Value对象log.Println(value2.Type()) //输出:Slog.Println(value2.Kind()) //输出:struct 变量i使用kind和type两个方法都输出了int,而结构体s的Type()方法输出了S,Kind()方法输出了struct，由此可以总结如下，如果你想拿到结构体里面定义的变量信息的时候，使用Type(f)方法。如果只是相判断是否是结构体时，就使用Kind() 2.获取变量的值和给变量赋值获取变量的值使用value.Interface()方法，该方法会返回一个value的值，不过类型是interface。给变量赋值需要先判断该变量的类型，使用之前提到过的Value.Kind()方法，如果变量的类型是reflect.Int，我们就可以使用Value.SetInt()方法给变量赋值。下面是一个例子： 1234567891011121314151617var i int = 1// 获取Value,这里注意,如果你要改变这个变量的话,需要传递变量的地址value := reflect.ValueOf(&amp;i)// value是一个指针,这里获取了该指针指向的值,相当于value.Elem()value = reflect.Indirect(value)// Interface是获取该value的值,返回的是一个interface对象log.Println(value.Interface()) // 输出:1// 把变量i的值设为2if value.Kind() == reflect.Int &#123; value.SetInt(2)&#125;log.Println(value.Interface()) // 输出:2 给结构体对象中的成员变量赋值的方法： 123456789101112131415161718192021222324252627type S struct &#123; A string // 注意:只有大写开头的成员变量可以Set&#125;s := S&#123;"x"&#125;value := reflect.ValueOf(&amp;s)value = reflect.Indirect(value)//value是结构体s,所以打印出来的是整个结构体的信息log.Println(value.Interface()) //输出: &#123;x&#125;f0 := value.FieldByName("A") //获取结构体s中第一个元素alog.Println(f0) // 输出: xif f0.Kind() == reflect.String &#123; if f0.CanSet() &#123; f0.SetString("y") &#125;&#125;log.Println(f0) // 输出: ylog.Println(value.Interface()) //输出: &#123;y&#125; 结构体这里需要注意的是，只有公有的成员变量可以被reflect改变值，私有的变量是无法改变值得。 3.获取结构体成员变量的tag信息由于golang变量大小写和公有私有息息相关，所以码农门很难按照自己的意愿来定义变量名。于是golang提供了tag机制，来给变量提供一个标签，这个标签可以作为一个别名，来给一些存储结构来获取结构体变量名字使用。下面是一个获取结构体成员变量tag信息的例子： 123456789101112131415161718type S struct &#123; A string `json:"tag_a"`&#125;s := S&#123;&#125;value := reflect.ValueOf(&amp;s)value = reflect.Indirect(value)//获取结构体s的类型Svt := value.Type()//获取S中的A成员变量f, _ := vt.FieldByName("A")//获取成员变量A的db标签log.Println(f.Tag.Get("json")) //输出: tag_a 未完待续。。。]]></content>
      <tags>
        <tag>golang</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Cocos2d-x中的灰度shader]]></title>
    <url>%2F2017%2F02%2F11%2Fcocos2d-x-gray-shader%2F</url>
    <content type="text"><![CDATA[灰度shader最近在学习shader，就把cocos2d-x 3.x版本中的很简单也很常用的灰度shader拿出来学习一下。 12345678910111213#ifdef GL_ESprecision mediump float; // ES版本的精度限定符，精度变低后可以提高效率#endifvarying vec4 v_fragmentColor;varying vec2 v_texCoord;void main(void) vec4 c = texture2D(CC_Texture0, v_texCoord); gl_FragColor.xyz = vec3(0.2126*c.r + 0.7152*c.g + 0.0722*c.b); gl_FragColor.w = c.w;&#125; 代码分析precision mediump float是open es特有的精度限定符，原本的浮点数精度是double，opengl es为了提高渲染效率，限定精度为float类型。 v_fragmentColor是从顶点着色器设置的颜色经过光栅化阶段的线性插值后传给片段着色器的颜色。 v_texCoord同样是经过线性插值而来的纹理坐标。 下面是顶点着色器的代码： 1234567891011121314151617181920const char* ccPositionTextureColor_noMVP_vert = STRINGIFY(attribute vec4 a_position;attribute vec2 a_texCoord;attribute vec4 a_color;\n#ifdef GL_ES\nvarying lowp vec4 v_fragmentColor;varying mediump vec2 v_texCoord;\n#else\nvarying vec4 v_fragmentColor;varying vec2 v_texCoord;\n#endif\nvoid main()&#123; gl_Position = CC_PMatrix * a_position; v_fragmentColor = a_color; v_texCoord = a_texCoord;&#125;); CC_Texture0是一个采样器，在load shader的时候，引擎会预先把这些uniform变量给加载进来。下面这部分代码就是引擎预先加载进来的uniform变量： 1234567891011121314static const char * COCOS2D_SHADER_UNIFORMS = "uniform mat4 CC_PMatrix;\n" "uniform mat4 CC_MVMatrix;\n" "uniform mat4 CC_MVPMatrix;\n" "uniform mat3 CC_NormalMatrix;\n" "uniform vec4 CC_Time;\n" "uniform vec4 CC_SinTime;\n" "uniform vec4 CC_CosTime;\n" "uniform vec4 CC_Random01;\n" "uniform sampler2D CC_Texture0;\n" "uniform sampler2D CC_Texture1;\n" "uniform sampler2D CC_Texture2;\n" "uniform sampler2D CC_Texture3;\n" "//CC INCLUDES END\n\n"; 这些变量在shader里面如果没有用到的话，会被引擎给优化掉。 texture2D()是shader的内建方法，作用是从CC_Texture0采样器中进行纹理采样，得到当前片段的颜色值。 gl_FragColor是shader的内建变量，表示当前片段的颜色，代码中是把从采样器中拿到的颜色值进行一个变灰处理后，最后得到的颜色值再赋值给gl_FragColor。gl_FragColor就是最终的颜色。 这个shader很简单，就是改变了一下rgb的值。0.2126，0.7152，0.0722这几个系数据说是根据人眼对rgb这三种基本颜色识别的强弱算出来的。 使用示例在cocos2dx 3.x版本中sprite变灰的代码例子：12auto sprite = Sprite::create("HelloWorld.png");sprite-&gt;setGLProgramState(GLProgramState::getOrCreateWithGLProgramName(GLProgram::SHADER_NAME_POSITION_GRAYSCALE)); 效果如下图所示：]]></content>
      <tags>
        <tag>cocos2d-x</tag>
        <tag>shader</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[【翻译】LPeg编程指南]]></title>
    <url>%2F2017%2F02%2F11%2Flua-lpeg%2F</url>
    <content type="text"><![CDATA[原文：http://www.inf.puc-rio.br/~roberto/lpeg/lpeg.html 译者序：这个是官方的LPeg的文档。这段时间学习LPeg的时候发现国内关于LPeg的文章很少，所以决定把文档翻译一下。 翻译的不是很完整，只是常用的一部分，会慢慢的翻译下去，有同学能帮我补全的话就太感谢了。 介绍：LPeg是lua中一个新的模式匹配（pattern-matching）的库，基于 Parsing Expression Grammars (PEGs)。本文是一个关于LPeg库的参考手册。关于更详细的文档，请看see A Text Pattern-Matching Tool based on Parsing Expression Grammars.，这里有关于实现的更详细的讨论。 根据 Snobol的传统，LPeg定义patterns作为第一级别对象，也就是说 patterns 可以作为常规的lua变量(represented by userdata)。 这个库提供了多种方式来创建和组合patterns。通过使用元方法，个别的一些函数可以提供类似中缀运算符或前缀运算符。一方面，相对于一般的正则表达式，LPeg匹配的结果通常更为详细。另一方面，第一级别的patterns可以更好的描写和扩展正则关系，我们可以定义函数来创建和组合patterns。 Operator Description lpeg.P(string) 匹配字符串 lpeg.P(n) 匹配n个字符串 lpeg.S(string) 匹配字符串中任意一个字符 (Set) lpeg.R(&quot;xy&quot;) 匹配x和y之间的任意一个字符(Range) patt^n 匹配至少n个``patt patt^-n 匹配最多n个``patt patt1 * patt2 先匹配patt1 然后接着匹配 patt2 patt1 + patt2 匹配满足patt1 或者满足patt2 (二选一) patt1 - patt2 匹配满足patt1而且不满足patt2 -patt 和 (&quot;&quot; - patt)一样 #patt Matches patt but consumes no input lpeg.B(patt) Matches patt behind the current position, consuming no input 举一个很简单的例子， lpeg.R(“09”)^1创建了一个pattern，这个pattern的作用是匹配一个非空的数字序列。再举一个稍微复杂一点的例子，-lpeg.P(1)匹配一个不能有任何字符的空字符串，这个通常用在匹配规则的最后。 Functionslpeg.match (pattern, subject [, init])匹配函数。它试图通过一个给定的pattern来对目标字符串进行匹配。如果匹配成功， 则返回匹配成功子串的第一个字符的位置，或者返回捕获的值（如果成功捕获到值的话）。 一个可选的数字参数 init 作为匹配目标字符串的起始位置。和通常的Lua库一样，如果参数是一个负数，则从目标字符串的最后一个字符开始向前计算，得到起始位置。 和典型的匹配函数不同， match 仅仅在一个固定的模式下工作； 也就是说，它试着从目标字符串的前缀字符开始匹配，而不是匹配任意的子串。.所以，如果我们想匹配一个任意位置的子串，就必须用Lua写一个循环来把目标字符串的每一个位置作为起始位置匹配，或者写一个pattern来匹配任意字符。两种方法对比来说，第二种非常方便、快捷和高效，可以以看看下面的例子。 lpeg.type (value)如果value是一个pattern，则返回一个字符串 “pattern”.，否则返回nil。 lpeg.version ()返回LPeg的字符串版本号。 lpeg.setmaxstack (max)设置堆栈的上限，默认是400。 Basic Constructions####lpeg.P (value) 用下面的规则将一个给定的值转换成一个合适的pattern： 如果参数是一个pattern，则返回参数pattern。 如果参数是一个string，则返回匹配这个字符串的pattern。 如果参数是一个非负整数 n, 则返回一个匹配正好是n个字符的字符串的pattern。 如果参数是一个负整数 -n, 则只有在输入的字符串还剩下不到n个字符才会成。 lpeg.P(-n) 等同于 -lpeg.P(n) (see the unary minus operation). 如果参数是一个 boolean, the result is a pattern that always succeeds or always fails (according to the boolean value), without consuming any input. 如果参数是一个table, 则被解读为一个grammar (see Grammars)。 如果参数是一个function, 则返回一个pattern，等价于一个 match-time capture 用一个空字符串匹配. lpeg.B(patt)Returns a pattern that matches only if the input string at the current position is preceded by patt. Pattern patt must match only strings with some fixed length, and it cannot contain captures.Like the and predicate, this pattern never consumes any input, independently of success or failure. lpeg.R ({range})返回一个在给定的范围内任何一个字符。范围是一个长度为2的字符串xy，返回的所有字符都是x和y对应ASCII编码之间（包括x和y）。 举个例子， pattern lpeg.R(“09”) 匹配所有的数字，lpeg.R(“az”, “AZ”) 匹配所有的ASCII字母。 lpeg.S (string)返回一个pattern匹配一个字符，这个字符是给定的string中的任何一个字符。 (The S stands for Set.) 举个例子， pattern lpeg.S(“+-*/“) 匹配任何一个算术运算符。 注意， 如果s是一个字符，那么 lpeg.P(s) 等价于 lpeg.S(s)。 lpeg.V (v)This operation creates a non-terminal (a variable) for a grammar. The created non-terminal refers to the rule indexed by v in the enclosing grammar. (See Grammars for details.)lpeg.locale ([table])Returns a table with patterns for matching some character classes according to the current locale. The table has fields named alnum, alpha, cntrl, digit, graph, lower, print, punct, space, upper, and xdigit, each one containing a correspondent pattern. Each pattern matches any single character that belongs to its class.If called with an argument table, then it creates those fields inside the given table and returns that table. #pattReturns a pattern that matches only if the input string matches patt, but without consuming any input, independently of success or failure. (This pattern is called an and predicate and it is equivalent to &amp;patt in the original PEG notation.)This pattern never produces any capture. -patt返回一个pattern，这个pattern要求输入的字符串不匹配patt。 它不消耗任何的输入，只是成功或者失败。 (This pattern is equivalent to !patt in the original PEG notation.)举个例子，pattern -lpeg.P(1) 匹配字符串的末尾。 这个pattern 从来不产生任何捕获，因为不是 patt失败就是 -patt 失败。 (一个失败的 pattern 从来不产生任何捕获 ) patt1 + patt2返回一个符合 patt1 或者 patt2的pattern。如果 patt1 和 patt2 都是字符集合, 则得到的结果是两个的并集。lower = lpeg.R(“az”)upper = lpeg.R(“AZ”)letter = lower + upper patt1 - patt2相当于 !patt2 patt1。 这个pattern 意思是不匹配 patt2 且匹配 patt1。如果成功了，则最后捕获到的是patt1的内容。这个pattern不会从patt2中捕获任何信息 (as either patt2 fails or patt1 - patt2 fails).如果 patt1 和 patt2 都是字符集合，那么这个运算就相当于集合差。 注意 -patt等价于 “” - patt (or 0 - patt). 如果 patt 是一个字符集合， 1 - patt是它的补集。 patt1 * patt2返回一个pattern，这个pattern先匹配patt1，patt1匹配完成之后，从匹配完成的下一个字符开始匹配patt2。 The identity element for this operation is the pattern lpeg.P(true), which always succeeds. (LPeg uses the * operator [instead of the more obvious ..] both because it has the right priority and because in formal languages it is common to use a dot for denoting concatenation.) patt^n如果 n 是一个非负数， 这个pattern等价于 pattn patt*。它匹配的条件是至少n个 patt。另外， 如果n 是负数， 这个 pattern 等价于 (patt?)__-n: 它匹配的条件是最多 |n| 个 patt。在个别情况下， 在原始的 PEG 中 ，patt^0 等价于 patt*, patt^1 等价于 patt+， patt^-1 等价于 patt?。在所有的情况下， the resulting pattern is greedy with no backtracking (also called a possessive repetition).注意，patt^n只会匹配最长的序列。 Grammar在lua的环境下，可以自定义一些patterns，让新定义的pattern可以使用已经定义过的旧的pattern，然而，这些技巧不允许定义循环的patterns。 For recursive patterns, we need real grammars.LPeg通过使用table来定义gramar， table的每个条目是一条规则。 Capturescapture 是一个pattern匹配成功之后捕获的值。 LPeg提供多种捕获方式， 基于pattern的匹配和组合来产生不同的捕获值。下面是捕获的基本概述： Operation What it Produces lpeg.C(patt) 所有pattern捕获的子串 lpeg.Carg(n) the value of the nth extra argument to lpeg.match (matches the empty string) lpeg.Cb(name) the values produced by the previous group capture named name (matches the empty string) lpeg.Cc(values) the given values (matches the empty string) lpeg.Cf(patt, func) 捕获的结果将作为参数依次被func调用 lpeg.Cg(patt [, name]) 把patt所有的返回值作为一个返回值并指定一个名字 lpeg.Cp() 捕获的位置 lpeg.Cs(patt) 创建一个替代捕获 lpeg.Ct(patt) 把patt中所有的返回值按照父子关系放到一个数组里返回 patt / string string, with some marks replaced by captures of patt patt / number the n-th value captured by patt, or no value when number is zero. patt / table table[c], where c is the (first) capture of patt patt / function the returns of function applied to the captures of patt lpeg.Cmt(patt, function) the returns of function applied to the captures of patt; the application is done at match time lpeg.C (patt)返回匹配到的子字符串以及patt内部子patt的返回值。 lpeg.Carg (n)Creates an argument capture. This pattern matches the empty string and produces the value given as the nth extra argument given in the call to lpeg.match. lpeg.Cb (name)Creates a back capture. This pattern matches the empty string and produces the values produced by the most recent group capture named name (where name can be any Lua value).Most recent means the last complete outermost group capture with the given name. A Complete capture means that the entire pattern corresponding to the capture has matched. An Outermost capture means that the capture is not inside another complete capture. lpeg.Cc ([value, …])Creates a constant capture. This pattern matches the empty string and produces all given values as its captured values. lpeg.Cf (patt, func)创建一个折叠的捕获，假设patt有n个返回值,C1,C2,C3,那么Cf返回 f(f( f(C1),C2), C3)。举个例子，一个用逗号隔开的数字序列，计算出数字串中每个数字相加的结果：– matches a numeral and captures its numerical valuenumber = lpeg.R”09”^1 / tonumber – matches a list of numbers, capturing their valueslist = number (“,” number)^0 – auxiliary function to add two numbersfunction add (acc, newvalue) return acc + newvalue end – folds the list of numbers adding themsum = lpeg.Cf(list, add) – example of useprint(sum:match(“10,30,43”)) –&gt; 83 lpeg.Cg (patt [, name])创建一个捕获的集合，这组返回的所有值型成一个捕获。集合可能是匿名(如果没有名字)或命名的(可以是任何非nil值Lua值)。 lpeg.Cp ()Creates a position capture. It matches the empty string and captures the position in the subject where the match occurs. The captured value is a number. lpeg.Cs (patt)Creates a substitution capture, which captures the substring of the subject that matches patt, with substitutions. For any capture inside patt with a value, the substring that matched the capture is replaced by the capture value (which should be a string). The final captured value is the string resulting from all replacements. lpeg.Ct (patt)创建一个捕获的数组。 创建一个表捕获;这个捕获将创建一个表,将匿名的捕获保存到表中,索引从1开始.对于命名组捕获,以组名为key。注：下面的内容由于开源中国已经翻译完成故不再翻译http://www.oschina.net/translate/lpeg-syntax]]></content>
      <tags>
        <tag>lua</tag>
        <tag>lpeg</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[golang中的rpc包用法]]></title>
    <url>%2F2017%2F02%2F11%2Fgolang-rpc%2F</url>
    <content type="text"><![CDATA[RPC，即 Remote Procedure Call（远程过程调用），说得通俗一点就是：调用远程计算机上的服务，就像调用本地服务一样。 我所在公司的项目是采用基于Restful的微服务架构，随着微服务之间的沟通越来越频繁，就希望可以做成用rpc来做内部的通讯，对外依然用Restful。于是就想到了golang标准库的rpc包和google的grpc。 这篇文章重点了解一下golang的rpc包。 介绍golang的rpc支持三个级别的RPC：TCP、HTTP、JSONRPC。但Go的RPC包是独一无二的RPC，它和传统的RPC系统不同，它只支持Go开发的服务器与客户端之间的交互，因为在内部，它们采用了Gob来编码。 Go RPC的函数只有符合下面的条件才能被远程访问，不然会被忽略，详细的要求如下： 函数必须是导出的(首字母大写) 必须有两个导出类型的参数， 第一个参数是接收的参数，第二个参数是返回给客- 户端的参数，第二个参数必须是指针类型的 函数还要有一个返回值error 举个例子，正确的RPC函数格式如下： 1func (t *T) MethodName(argType T1, replyType *T2) error T、T1和T2类型必须能被encoding/gob包编解码。 示例举一个http的例子。 下面是http服务器端的代码： 1234567891011121314151617181920212223242526272829303132333435363738394041424344package mainimport ( "errors" "net" "net/rpc" "log" "net/http")type Args struct &#123; A, B int&#125;type Quotient struct &#123; Quo, Rem int&#125;type Arith intfunc (t *Arith) Multiply(args *Args, reply *int) error &#123; *reply = args.A * args.B return nil&#125;func (t *Arith) Divide(args *Args, quo *Quotient) error &#123; if args.B == 0 &#123; return errors.New("divide by zero") &#125; quo.Quo = args.A / args.B quo.Rem = args.A % args.B return nil&#125;func main() &#123; arith := new(Arith) rpc.Register(arith) rpc.HandleHTTP() l, e := net.Listen("tcp", ":1234") if e != nil &#123; log.Fatal("listen error:", e) &#125; http.Serve(l, nil)&#125; 简单分析一下上面的例子，先实例化了一个Arith对象arith，然后给arith注册了rpc服务，然后把rpc挂载到http服务上面，当http服务打开的时候我们就可以通过rpc客户端来调用arith中符合rpc标准的的方法了。 请看客户端的代码： 1234567891011121314151617181920212223242526272829303132333435363738394041package mainimport ( "net/rpc" "log" "fmt")type Args struct &#123; A, B int&#125;type Quotient struct &#123; Quo, Rem int&#125;func main() &#123; client, err := rpc.DialHTTP("tcp", "127.0.0.1:1234") if err != nil &#123; log.Fatal("dialing:", err) &#125; // Synchronous call args := &amp;Args&#123;7,8&#125; var reply int err = client.Call("Arith.Multiply", args, &amp;reply) if err != nil &#123; log.Fatal("arith error:", err) &#125; fmt.Printf("Arith: %d*%d=%d\n", args.A, args.B, reply) // Asynchronous call quotient := new(Quotient) divCall := client.Go("Arith.Divide", args, quotient, nil) replyCall := &lt;-divCall.Done // will be equal to divCall if replyCall.Error != nil &#123; log.Fatal("arith error:", replyCall.Error) &#125; fmt.Printf("Arith: %d/%d=%d...%d", args.A, args.B, quotient.Quo, quotient.Rem) // check errors, print, etc.&#125; 简单说明下，先用rpc的DialHTTP方法连接服务器端，调用服务器端的函数就要使用Call方法了，Call方法的参数和返回值已经很清晰的表述出rpc整体的调用逻辑了。 我们把服务器端跑起来，再把客户端跑起来，这时候客户端会输出： 12Arith: 7*8=56Arith: 7/8=0...7 到此，整个rpc的调用逻辑就完成了。]]></content>
      <tags>
        <tag>golang</tag>
        <tag>rpc</tag>
      </tags>
  </entry>
</search>
